{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Multivarient LSTM"
      ],
      "metadata": {
        "id": "eGtFiPbNMhxr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from datetime import datetime, timedelta"
      ],
      "metadata": {
        "id": "UaGkfwaxUHgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Learning rate scheduler\n",
        "def scheduler(epoch, lr):\n",
        "    if epoch < 10:\n",
        "        return lr\n",
        "    else:\n",
        "        return lr * np.exp(-0.1)\n",
        "\n",
        "# Manual RSI calculation\n",
        "def compute_rsi(data, periods=14):\n",
        "    delta = data.diff()\n",
        "    gain = (delta.where(delta > 0, 0)).rolling(window=periods).mean()\n",
        "    loss = (-delta.where(delta < 0, 0)).rolling(window=periods).mean()\n",
        "    rs = gain / loss\n",
        "    rsi = 100 - (100 / (1 + rs))\n",
        "    return rsi\n",
        "\n",
        "# Manual SMA calculation\n",
        "def compute_sma(data, periods):\n",
        "    return data.rolling(window=periods).mean()"
      ],
      "metadata": {
        "id": "h0MHBYroULEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetch GOOGL and S&P 500 data up to yesterday\n",
        "end_date = '2025-04-14'\n",
        "start_date = '2022-01-01'\n",
        "googl_data = yf.download('GOOGL', start=start_date, end=end_date)\n",
        "sp500_data = yf.download('^GSPC', start=start_date, end=end_date)\n",
        "\n",
        "# Combine relevant features\n",
        "data = googl_data[['Open', 'High', 'Low', 'Close', 'Volume']].copy()\n",
        "data['SP500_Close'] = sp500_data['Close']\n",
        "\n",
        "# Add manual technical indicators\n",
        "data['RSI'] = compute_rsi(data['Close'], periods=14)\n",
        "data['SMA_20'] = compute_sma(data['Close'], periods=20)\n",
        "data['SMA_50'] = compute_sma(data['Close'], periods=50)\n",
        "\n",
        "# Handle missing values\n",
        "data = data.dropna()\n",
        "\n",
        "# Normalize the data\n",
        "scaler = MinMaxScaler()\n",
        "scaled_data = scaler.fit_transform(data)\n",
        "\n",
        "# Prepare sequences for LSTM (120-day lookback)\n",
        "def create_sequences(data, seq_length):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - seq_length):\n",
        "        X.append(data[i:i + seq_length])\n",
        "        y.append(data[i + seq_length, 3])  # Predict Close price (index 3)\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "seq_length = 120\n",
        "X, y = create_sequences(scaled_data, seq_length)\n",
        "\n",
        "# Split into train and test sets (80% train, 20% test)\n",
        "train_size = int(len(X) * 0.8)\n",
        "X_train, X_test = X[:train_size], X[train_size:]\n",
        "y_train, y_test = y[:train_size], y[train_size:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubtt7MpBUOCQ",
        "outputId": "936e0d8e-f690-4b67-e925-54cbc4308e59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YF.download() has changed argument auto_adjust default to True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build LSTM model\n",
        "model = Sequential([\n",
        "    LSTM(100, return_sequences=True, input_shape=(seq_length, X.shape[2])),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "    LSTM(100, return_sequences=True),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "    LSTM(50),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "    Dense(50, activation='relu'),\n",
        "    Dense(1)\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IqAViRAURmg",
        "outputId": "71d9102c-a946-4375-c163-048139e184c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile model\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=optimizer, loss='mse')\n",
        "\n",
        "# Train the model\n",
        "callbacks = [LearningRateScheduler(scheduler)]\n",
        "model.fit(X_train, y_train, epochs=40, batch_size=32, validation_split=0.1, callbacks=callbacks, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMATDQDoUWxF",
        "outputId": "91a49f95-22c0-4e28-f0a8-d01301fc532a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 63ms/step - loss: 0.5305 - val_loss: 0.4196 - learning_rate: 0.0010\n",
            "Epoch 2/40\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.2140 - val_loss: 0.3225 - learning_rate: 0.0010\n",
            "Epoch 3/40\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.1715 - val_loss: 0.3528 - learning_rate: 0.0010\n",
            "Epoch 4/40\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1140 - val_loss: 0.2648 - learning_rate: 0.0010\n",
            "Epoch 5/40\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0976 - val_loss: 0.1927 - learning_rate: 0.0010\n",
            "Epoch 6/40\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0977 - val_loss: 0.2344 - learning_rate: 0.0010\n",
            "Epoch 7/40\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0712 - val_loss: 0.1556 - learning_rate: 0.0010\n",
            "Epoch 8/40\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0690 - val_loss: 0.2862 - learning_rate: 0.0010\n",
            "Epoch 9/40\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0563 - val_loss: 0.2729 - learning_rate: 0.0010\n",
            "Epoch 10/40\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0579 - val_loss: 0.2085 - learning_rate: 0.0010\n",
            "Epoch 11/40\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0506 - val_loss: 0.2070 - learning_rate: 9.0484e-04\n",
            "Epoch 12/40\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0405 - val_loss: 0.1806 - learning_rate: 8.1873e-04\n",
            "Epoch 13/40\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0449 - val_loss: 0.1563 - learning_rate: 7.4082e-04\n",
            "Epoch 14/40\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0337 - val_loss: 0.2077 - learning_rate: 6.7032e-04\n",
            "Epoch 15/40\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0398 - val_loss: 0.1431 - learning_rate: 6.0653e-04\n",
            "Epoch 16/40\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0346 - val_loss: 0.1861 - learning_rate: 5.4881e-04\n",
            "Epoch 17/40\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0333 - val_loss: 0.1812 - learning_rate: 4.9659e-04\n",
            "Epoch 18/40\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0330 - val_loss: 0.1663 - learning_rate: 4.4933e-04\n",
            "Epoch 19/40\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0320 - val_loss: 0.1978 - learning_rate: 4.0657e-04\n",
            "Epoch 20/40\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0292 - val_loss: 0.1440 - learning_rate: 3.6788e-04\n",
            "Epoch 21/40\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0275 - val_loss: 0.1288 - learning_rate: 3.3287e-04\n",
            "Epoch 22/40\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0306 - val_loss: 0.1155 - learning_rate: 3.0119e-04\n",
            "Epoch 23/40\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0251 - val_loss: 0.1148 - learning_rate: 2.7253e-04\n",
            "Epoch 24/40\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0244 - val_loss: 0.1057 - learning_rate: 2.4660e-04\n",
            "Epoch 25/40\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0272 - val_loss: 0.0695 - learning_rate: 2.2313e-04\n",
            "Epoch 26/40\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0213 - val_loss: 0.0518 - learning_rate: 2.0190e-04\n",
            "Epoch 27/40\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0264 - val_loss: 0.0336 - learning_rate: 1.8268e-04\n",
            "Epoch 28/40\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0229 - val_loss: 0.0313 - learning_rate: 1.6530e-04\n",
            "Epoch 29/40\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0272 - val_loss: 0.0286 - learning_rate: 1.4957e-04\n",
            "Epoch 30/40\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0288 - val_loss: 0.0252 - learning_rate: 1.3534e-04\n",
            "Epoch 31/40\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0258 - val_loss: 0.0133 - learning_rate: 1.2246e-04\n",
            "Epoch 32/40\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0264 - val_loss: 0.0215 - learning_rate: 1.1080e-04\n",
            "Epoch 33/40\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0261 - val_loss: 0.0166 - learning_rate: 1.0026e-04\n",
            "Epoch 34/40\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0219 - val_loss: 0.0133 - learning_rate: 9.0718e-05\n",
            "Epoch 35/40\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0252 - val_loss: 0.0075 - learning_rate: 8.2085e-05\n",
            "Epoch 36/40\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0223 - val_loss: 0.0044 - learning_rate: 7.4274e-05\n",
            "Epoch 37/40\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0192 - val_loss: 0.0040 - learning_rate: 6.7206e-05\n",
            "Epoch 38/40\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0214 - val_loss: 0.0026 - learning_rate: 6.0810e-05\n",
            "Epoch 39/40\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0228 - val_loss: 0.0023 - learning_rate: 5.5023e-05\n",
            "Epoch 40/40\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0217 - val_loss: 0.0021 - learning_rate: 4.9787e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x79be7e292210>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model on test set\n",
        "y_pred = model.predict(X_test)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "print(f\"Test MAE: {mae:.4f}, Test RMSE: {rmse:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZdvMJhkUYzo",
        "outputId": "c1f4dc14-6449-4893-e364-27a6b7776df0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step\n",
            "Test MAE: 0.0968, Test RMSE: 0.1250\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare input for predicting today's price (April 15, 2025)\n",
        "last_sequence = scaled_data[-seq_length:]  # Last 120 days up to April 14\n",
        "last_sequence = last_sequence.reshape(1, seq_length, last_sequence.shape[1])\n",
        "\n",
        "# Predict today's Close price\n",
        "predicted_scaled = model.predict(last_sequence)\n",
        "\n",
        "# Inverse transform to get actual price\n",
        "dummy = np.zeros((1, data.shape[1]))\n",
        "dummy[0, 3] = predicted_scaled[0, 0]\n",
        "predicted_price = scaler.inverse_transform(dummy)[0, 3]\n",
        "\n",
        "print(f\"Predicted GOOGL Close price for April 15, 2025: ${predicted_price:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YlTH7l7UUYk",
        "outputId": "09dbafda-8dbc-4aec-a3e8-13d96149de19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Predicted GOOGL Close price for April 15, 2025: $157.56\n"
          ]
        }
      ]
    }
  ]
}